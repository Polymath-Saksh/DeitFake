{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "tpuV5e8",
      "dataSources": [
        {
          "sourceId": 10125851,
          "sourceType": "datasetVersion",
          "datasetId": 6248577
        }
      ],
      "dockerImageVersionId": 31194,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "accelerator": "TPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "xdxd003_ff_c23_path = kagglehub.dataset_download('xdxd003/ff-c23')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Ir50SZigaXSh",
        "outputId": "6d186ece-ae35-42f9-fe37-ef18f9a2b548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'ff-c23' dataset.\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Uninstall the mismatched versions\n",
        "# %pip uninstall -y torch torchvision torchaudio torch_xla\n",
        "\n",
        "# 2. Reinstall the TPU-compatible PyTorch (compatible with Colab/Kaggle TPUs)\n",
        "# %pip install torch_xla[tpu] torch torchvision\n",
        "\n",
        "# 3. Reinstall facenet-pytorch WITHOUT dependencies (so it doesn't break PyTorch again)\n",
        "%pip install facenet-pytorch opencv-python --no-deps"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-03T13:14:04.087145Z",
          "iopub.execute_input": "2025-12-03T13:14:04.087537Z",
          "iopub.status.idle": "2025-12-03T13:14:07.924412Z",
          "shell.execute_reply.started": "2025-12-03T13:14:04.087506Z",
          "shell.execute_reply": "2025-12-03T13:14:07.923586Z"
        },
        "id": "GlvFQr0kaXSh",
        "outputId": "339c5a8b-8c33-4844-b386-f6dd7565f36c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: facenet-pytorch, opencv-python\n",
            "Successfully installed facenet-pytorch-2.6.0 opencv-python-4.12.0.88\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageOps\n",
        "from transformers import AutoModelForImageClassification, AutoImageProcessor\n",
        "from facenet_pytorch import MTCNN\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# =================CONFIGURATION=================\n",
        "DATASET_ROOT = \"/kaggle/input/ff-c23/FaceForensics++_C23/\"\n",
        "CSV_FOLDER = os.path.join(DATASET_ROOT, \"csv\")\n",
        "\n",
        "MODEL_ID = \"sakshamkr1/deitfake-v2\"\n",
        "\n",
        "# High-Accuracy Settings\n",
        "FRAMES_PER_VIDEO = 15\n",
        "BATCH_SIZE = 1\n",
        "NUM_WORKERS = 8\n",
        "MARGIN = 1.3  # Critical: Capture blending boundaries\n",
        "ENABLE_TTA = True # Robustness: Average predictions of original + flipped image\n",
        "\n",
        "# If True, only validates on the Official FF++ Test Split (IDs 860-999)\n",
        "USE_OFFICIAL_TEST_SPLIT = True\n",
        "\n",
        "# Manipulations to test. Must match CSV filenames (e.g., 'Deepfakes.csv')\n",
        "TARGET_MANIPULATIONS = ['Deepfakes', 'Face2Face', 'FaceShifter', 'FaceSwap', 'NeuralTextures']\n",
        "# ===============================================\n",
        "\n",
        "# Check Device\n",
        "try:\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    DEVICE = xm.xla_device()\n",
        "    print(f\"--- Running on TPU: {DEVICE} ---\")\n",
        "except:\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"--- Running on Device: {DEVICE} ---\")\n",
        "\n",
        "class FFPPDataset(Dataset):\n",
        "    def __init__(self, video_paths, labels, processor, frames_per_video=10, mtcnn=None):\n",
        "        self.video_paths = video_paths\n",
        "        self.labels = labels\n",
        "        self.processor = processor\n",
        "        self.frames_per_video = frames_per_video\n",
        "        self.mtcnn = mtcnn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_paths)\n",
        "\n",
        "    def extract_faces_high_res(self, video_path):\n",
        "        \"\"\"\n",
        "        High-Accuracy Extraction:\n",
        "        1. Reads full resolution frames.\n",
        "        2. Detects faces without downscaling.\n",
        "        3. Applies a 1.3x margin to capture blending artifacts.\n",
        "        \"\"\"\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened(): return []\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        if total_frames <= 0: return []\n",
        "\n",
        "        frame_indices = np.linspace(0, total_frames - 1, self.frames_per_video, dtype=int)\n",
        "        frames_pil = []\n",
        "\n",
        "        for idx in frame_indices:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "            ret, frame = cap.read()\n",
        "            if not ret: continue\n",
        "\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frames_pil.append(Image.fromarray(frame_rgb))\n",
        "\n",
        "        cap.release()\n",
        "        if not frames_pil: return []\n",
        "\n",
        "        # Batch Detection\n",
        "        try:\n",
        "            boxes_list, _ = self.mtcnn.detect(frames_pil)\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "        final_faces = []\n",
        "        for i, boxes in enumerate(boxes_list):\n",
        "            if boxes is not None:\n",
        "                # Select largest face\n",
        "                box = boxes[0]\n",
        "\n",
        "                # --- APPLY MARGIN ---\n",
        "                x1, y1, x2, y2 = box\n",
        "                w = x2 - x1\n",
        "                h = y2 - y1\n",
        "                cx = x1 + w / 2\n",
        "                cy = y1 + h / 2\n",
        "\n",
        "                new_w = w * MARGIN\n",
        "                new_h = h * MARGIN\n",
        "\n",
        "                x1 = max(0, cx - new_w / 2)\n",
        "                y1 = max(0, cy - new_h / 2)\n",
        "                x2 = min(frames_pil[i].width, cx + new_w / 2)\n",
        "                y2 = min(frames_pil[i].height, cy + new_h / 2)\n",
        "\n",
        "                face = frames_pil[i].crop((x1, y1, x2, y2))\n",
        "                face = face.resize((224, 224), Image.Resampling.BILINEAR)\n",
        "                final_faces.append(face)\n",
        "\n",
        "        return final_faces\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = self.video_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if not os.path.exists(video_path): return None\n",
        "\n",
        "        faces = self.extract_faces_high_res(video_path)\n",
        "        if not faces: return None\n",
        "\n",
        "        # --- Test Time Augmentation (TTA) Logic ---\n",
        "        if ENABLE_TTA:\n",
        "            # Create flipped versions\n",
        "            flipped_faces = [ImageOps.mirror(f) for f in faces]\n",
        "            all_faces = faces + flipped_faces\n",
        "            inputs = self.processor(images=all_faces, return_tensors=\"pt\")\n",
        "        else:\n",
        "            inputs = self.processor(images=faces, return_tensors=\"pt\")\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": inputs[\"pixel_values\"],\n",
        "            \"label\": torch.tensor(label, dtype=torch.long),\n",
        "            \"video_path\": video_path\n",
        "        }\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if len(batch) == 0: return None\n",
        "    return batch\n",
        "\n",
        "def is_test_video(filename):\n",
        "    \"\"\"Filter for Test Split (IDs 860-999)\"\"\"\n",
        "    try:\n",
        "        name = os.path.basename(filename)\n",
        "        name = os.path.splitext(name)[0]\n",
        "        parts = name.split('_')\n",
        "        video_id = int(parts[0])\n",
        "        return video_id >= 860\n",
        "    except:\n",
        "        return True\n",
        "\n",
        "def load_paths_from_csv():\n",
        "    real_paths = []\n",
        "    fake_paths = []\n",
        "\n",
        "    print(f\"--- Loading paths from CSVs in {CSV_FOLDER} ---\")\n",
        "\n",
        "    # 1. Load REAL videos (original.csv)\n",
        "    orig_csv_path = os.path.join(CSV_FOLDER, \"original.csv\")\n",
        "    if os.path.exists(orig_csv_path):\n",
        "        df = pd.read_csv(orig_csv_path)\n",
        "        for _, row in df.iterrows():\n",
        "            rel_path = row['File Path']\n",
        "            full_path = os.path.join(DATASET_ROOT, rel_path)\n",
        "\n",
        "            if USE_OFFICIAL_TEST_SPLIT and not is_test_video(rel_path):\n",
        "                continue\n",
        "            real_paths.append(full_path)\n",
        "    else:\n",
        "        print(\"!! WARNING: original.csv not found!\")\n",
        "\n",
        "    # 2. Load FAKE videos\n",
        "    for manip in TARGET_MANIPULATIONS:\n",
        "        csv_path = os.path.join(CSV_FOLDER, f\"{manip}.csv\")\n",
        "        if os.path.exists(csv_path):\n",
        "            df = pd.read_csv(csv_path)\n",
        "            for _, row in df.iterrows():\n",
        "                rel_path = row['File Path']\n",
        "                full_path = os.path.join(DATASET_ROOT, rel_path)\n",
        "\n",
        "                if USE_OFFICIAL_TEST_SPLIT and not is_test_video(rel_path):\n",
        "                    continue\n",
        "                fake_paths.append(full_path)\n",
        "        else:\n",
        "            print(f\"Skipping {manip} (CSV not found)\")\n",
        "\n",
        "    print(f\"Loaded {len(real_paths)} Real and {len(fake_paths)} Fake videos from CSVs.\")\n",
        "\n",
        "    paths = real_paths + fake_paths\n",
        "    # Standard Metrics: 0=Real, 1=Fake\n",
        "    labels = [0] * len(real_paths) + [1] * len(fake_paths)\n",
        "    return paths, labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9sxMnazgsxT",
        "outputId": "2d2408d2-46a2-4873-f961-c17cfe559ab2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-3059091744.py:36: DeprecationWarning: Use torch_xla.device instead\n",
            "  DEVICE = xm.xla_device()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Running on TPU: xla:0 ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    print(f\"--- Loading DeitFake: {MODEL_ID} ---\")\n",
        "    processor = AutoImageProcessor.from_pretrained(MODEL_ID,use_fast=1)\n",
        "    model = AutoModelForImageClassification.from_pretrained(MODEL_ID)\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Model ID2LABEL: {model.config.id2label}\")\n",
        "\n",
        "    print(\"--- Init MTCNN (High Accuracy) ---\")\n",
        "    mtcnn_device = torch.device(\"cpu\") if \"xla\" in str(DEVICE) else DEVICE\n",
        "    mtcnn = MTCNN(\n",
        "        keep_all=False,\n",
        "        select_largest=True,\n",
        "        device=mtcnn_device,\n",
        "        thresholds=[0.6, 0.7, 0.7]\n",
        "    )\n",
        "\n",
        "    # Use CSV loader\n",
        "    video_paths, labels = load_paths_from_csv()\n",
        "\n",
        "    if not video_paths:\n",
        "        print(\"No videos found! Check CSV_FOLDER path.\")\n",
        "        return\n",
        "\n",
        "    dataset = FFPPDataset(video_paths, labels, processor, FRAMES_PER_VIDEO, mtcnn)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, num_workers=NUM_WORKERS)\n",
        "\n",
        "    print(f\"--- Starting Validation (TTA Enabled: {ENABLE_TTA}) ---\")\n",
        "\n",
        "    y_true = []\n",
        "    y_scores = []\n",
        "    results = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader):\n",
        "            if batch is None: continue\n",
        "            data = batch[0]\n",
        "\n",
        "            pixel_values = data[\"pixel_values\"].to(DEVICE)\n",
        "            label = data[\"label\"].item()\n",
        "            path = data[\"video_path\"]\n",
        "\n",
        "            outputs = model(pixel_values)\n",
        "            probs = torch.softmax(outputs.logits, dim=1)\n",
        "\n",
        "            # === CRITICAL FIX ===\n",
        "            # Your Model: Index 0 = Fake, Index 1 = Real\n",
        "            # Validation Script Target: 1 = Fake, 0 = Real\n",
        "            # Therefore: We want the probability of Index 0 (Fake)\n",
        "            fake_prob = probs[:, 0].mean().item()\n",
        "\n",
        "            y_true.append(label)\n",
        "            y_scores.append(fake_prob)\n",
        "            results.append({\"video\": os.path.basename(path), \"label\": label, \"score\": fake_prob})\n",
        "\n",
        "    # Save results\n",
        "    df_res = pd.DataFrame(results)\n",
        "    df_res.to_csv(\"ffpp_results_high_acc.csv\", index=False)\n",
        "\n",
        "    y_pred_binary = (np.array(y_scores) > 0.5).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred_binary)\n",
        "    auc = roc_auc_score(y_true, y_scores)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(f\"ACCURACY: {acc:.4f}\")\n",
        "    print(f\"AUC:      {auc:.4f}\")\n",
        "    print(\"=\"*30)\n",
        "    print(classification_report(y_true, y_pred_binary, target_names=[\"Real\", \"Fake\"]))\n"
      ],
      "metadata": {
        "id": "WcO7VsBaB4kC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTHBjUkfBzoh",
        "outputId": "692b8dbb-211d-473d-aee3-7bfc0f1c44c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading DeitFake: sakshamkr1/deitfake-v2 ---\n",
            "Model ID2LABEL: {0: 'Fake', 1: 'Real'}\n",
            "--- Init MTCNN (High Accuracy) ---\n",
            "--- Loading paths from CSVs in /kaggle/input/ff-c23/FaceForensics++_C23/csv ---\n",
            "Loaded 140 Real and 700 Fake videos from CSVs.\n",
            "--- Starting Validation (TTA Enabled: True) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 840/840 [37:46<00:00,  2.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "ACCURACY: 0.7190\n",
            "AUC:      0.5240\n",
            "==============================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.16      0.16      0.16       140\n",
            "        Fake       0.83      0.83      0.83       700\n",
            "\n",
            "    accuracy                           0.72       840\n",
            "   macro avg       0.49      0.49      0.49       840\n",
            "weighted avg       0.72      0.72      0.72       840\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}